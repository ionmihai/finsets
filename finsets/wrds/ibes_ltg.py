# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/01_wrds/06_ibes_ltg.ipynb.

# %% ../../nbs/01_wrds/06_ibes_ltg.ipynb 3
from __future__ import annotations
from pathlib import Path
from typing import List
import os

import pandas as pd
import numpy as np

import pandasmore as pdm
from . import wrds_api
from .. import RESOURCES

# %% auto 0
__all__ = ['PROVIDER', 'URL', 'LIBRARY', 'TABLE', 'LINK_LIBRARY', 'LINK_TABLE', 'FREQ', 'MIN_YEAR', 'MAX_YEAR',
           'ENTITY_ID_IN_RAW_DSET', 'ENTITY_ID_IN_CLEAN_DSET', 'TIME_VAR_IN_RAW_DSET', 'TIME_VAR_IN_CLEAN_DSET',
           'LABELS_FILE', 'raw_metadata', 'default_raw_vars', 'parse_varlist', 'download']

# %% ../../nbs/01_wrds/06_ibes_ltg.ipynb 4
PROVIDER = 'Refinitiv via WRDS'
URL = 'https://wrds-www.wharton.upenn.edu/pages/get-data/ibes-thomson-reuters/ibes-academic/unadjusted-detail/history/'
LIBRARY = 'ibes'
TABLE = 'detu_epsus'
LINK_LIBRARY = 'wrdsapps_link_crsp_ibes'
LINK_TABLE = 'ibcrsphist'
FREQ = 'M'
MIN_YEAR = 1925
MAX_YEAR = None
ENTITY_ID_IN_RAW_DSET = 'permno'
ENTITY_ID_IN_CLEAN_DSET = 'permno'
TIME_VAR_IN_RAW_DSET = 'date'
TIME_VAR_IN_CLEAN_DSET = 'Mdate'
LABELS_FILE = RESOURCES/'ibes_detu_epsus_variable_descriptions.csv'

# %% ../../nbs/01_wrds/06_ibes_ltg.ipynb 5
def raw_metadata(wrds_username: str=None
             ) -> pd.DataFrame:
    "Collects metadata from WRDS `{LIBRARY}.{TABLE}` table and merges it with variable labels from LABELS_FILE"

    # Get metadata from `{LIBRARY}.{TABLE}`
    if wrds_username is None:
        wrds_username = os.getenv('WRDS_USERNAME')
        if wrds_username is None: wrds_username = input("Enter your WRDS username: ") 

    try:
        db = wrds_api.Connection(wrds_username = wrds_username)
        funda = db.describe_table(LIBRARY,TABLE)
        nr_rows = db.get_row_count(LIBRARY,TABLE)
    finally:
        db.close()

    meta = funda[['name','type']].copy()
    meta['nr_rows'] = nr_rows
    meta['wrds_library'] = LIBRARY
    meta['wrds_table'] = TABLE

    # Get variable labels from LABELS_FILE
    df = pd.read_csv(LABELS_FILE)
    df['Variable Label'] = df.apply(lambda row: row['Description'].replace(row['Variable Name'].strip()+' -- ', ''), axis=1)
    df['Variable Label'] = df.apply(lambda row: row['Variable Label'].replace( '(' + row['Variable Name'].strip() + ')', ''), axis=1)
    df['Variable Name'] = df['Variable Name'].str.strip().str.lower()
    df = df[['Variable Name', 'Variable Label']].copy()
    df.columns = ['name','label']
    
    # Merge metadata and variable labels and clean up a bit
    meta = meta.merge(df, how='left', on='name')
    meta['output_of'] = 'wrds.ibes_ltg.download'
    meta = pdm.order_columns(meta,these_first=['name','label','output_of'])
    for v in list(meta.columns):
        meta[v] = meta[v].astype('string')
    
    return meta

# %% ../../nbs/01_wrds/06_ibes_ltg.ipynb 7
def default_raw_vars():
    return ['ticker', 'value', 'fpi', 'anndats', 'fpedats', 'revdats', 'actdats', 'estimator', 'analys', 'pdf']

# %% ../../nbs/01_wrds/06_ibes_ltg.ipynb 8
def parse_varlist(vars: List[str]=None, #list of variables requested by user
                  req_vars: List[str] = ['ticker', 'anndats'], #list of variables that will automatically get downloaded, even if not in `vars`
                  prefix: str='a.', #string to add in front of each variable name when we build the SQL string of variable names
                  ) -> str:
    """Add required variables to requested variables, validate them, and build the sql string with their names"""

    # Build full list of variables that will be downloaded
    if vars is None: vars = default_raw_vars()
    if req_vars is None: req_vars = []
    vars =  req_vars + [x for x in vars if x not in req_vars] #in case `vars` already contains some of the required variables

    # Validate variables to be downloaded (make sure that they are in the target database)
    valid_vars = list(raw_metadata().name)
    invalid_vars = [v for v in vars if v not in valid_vars]
    if invalid_vars: raise ValueError(f"These vars are not in the database: {invalid_vars}") 

    return ','.join([f'{prefix}{var_name}' for var_name in vars])

# %% ../../nbs/01_wrds/06_ibes_ltg.ipynb 9
def download(vars: List[str]=None, # If None, downloads `default_raw_vars`; `permno`, `ticker`, and `anndats` added by default
             obs_limit: int=None, #Number of rows to download. If None, full dataset will be downloaded
             wrds_username: str=None, #If None, looks for WRDS_USERNAME with `os.getenv`, then prompts you if needed
             start_date: str=None, # Start date in MM/DD/YYYY format
             end_date: str=None, #End date in MM/DD/YYYY format; if None, defaults to current date
             permno_match_score: tuple=(1,), #accuracy of permno-ibes link. 1-6. 1 is best. use >1 with caution.
             ) -> pd.DataFrame:
    """Downloads `vars` from `start_date` to `end_date` from WRDS `ibes.detu_epsus` library and adds PERMNO from CRSP"""

    vars = parse_varlist(vars)

    sql_string=f"""SELECT {vars}, b.permno
                        FROM {LIBRARY}.{TABLE} AS a
                        LEFT JOIN {LINK_LIBRARY}.{LINK_TABLE} AS b
                        ON a.ticker = b.ticker
                        WHERE a.anndats BETWEEN b.sdate AND b.edate
                                AND fpi='0'
                """
    if permno_match_score is not None: sql_string += r" AND score IN %(permno_match_score)s"
    if start_date is not None: sql_string += r" AND anndats >= %(start_date)s"
    if end_date is not None: sql_string += r" AND anndats <= %(end_date)s"
    if obs_limit is not None: sql_string += r" LIMIT %(obs_limit)s"

    return wrds_api.download(sql_string, wrds_username=wrds_username, 
                             params={'permno_match_score': permno_match_score,
                                 'start_date':start_date, 'end_date':end_date, 'obs_limit':obs_limit})
